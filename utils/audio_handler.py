import streamlit as st
import os
from datetime import datetime

def save_uploaded_audio(uploaded_file, session_id, step_number):
    """
    Spara uppladdad ljudfil (wav/mp3) p√• disk under data/audio.
    """
    if not os.path.exists('data/audio'):
        os.makedirs('data/audio')
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    file_extension = uploaded_file.name.split('.')[-1]
    filename = f"session_{session_id}_steg_{step_number}_{timestamp}.{file_extension}"
    filepath = os.path.join('data/audio', filename)
    
    with open(filepath, 'wb') as f:
        f.write(uploaded_file.getbuffer())
    
    return filepath

def save_recorded_audio(audio_bytes: bytes, session_id, step_number):
    """
    Spara bin√§rt wav‚Äêinneh√•ll (bytes) som spelats in via streamlit_audio_recorder.
    Returnerar s√∂kv√§g till sparad fil.
    """
    if not audio_bytes:
        return None

    if not os.path.exists('data/audio'):
        os.makedirs('data/audio')
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"session_{session_id}_steg_{step_number}_recorded_{timestamp}.wav"
    filepath = os.path.join('data/audio', filename)
    
    with open(filepath, 'wb') as f:
        f.write(audio_bytes)
    
    return filepath

def transcribe_uploaded_file(uploaded_file, session_id, step_number):
    """
    Spara och transkribera en uppladdad ljudfil.
    Returnerar tuple: (transcription_text, audio_file_path)
    """
    try:
        # Spara filen f√∂rst
        audio_path = save_uploaded_audio(uploaded_file, session_id, step_number)
        
        if audio_path:
            # Kontrollera filstorlek
            file_size_mb = uploaded_file.size / (1024 * 1024)
            st.info(f"üìä Filstorlek: {file_size_mb:.1f} MB")
            
            # Anv√§nd segmenterad transkribering f√∂r stora filer
            if file_size_mb > 20:  # Om filen √§r st√∂rre √§n 20 MB
                st.info("üîÑ Stor fil uppt√§ckt - anv√§nder segmenterad transkribering f√∂r b√§sta resultat...")
                transcription = transcribe_large_audio_file(audio_path)
            else:
                # Transkribera normalt f√∂r mindre filer
                transcription = transcribe_audio_openai(audio_path)
            
            return transcription, audio_path
        else:
            return None, None
            
    except Exception as e:
        st.error(f"Fel vid hantering av uppladdad fil: {e}")
        return None, None

def transcribe_audio_openai(audio_file_path):
    """
    Transkribera en sparad ljudfil med OpenAI Whisper-API.
    Returnerar transkribering som str√§ng eller None vid fel.
    """
    try:
        from openai import OpenAI
        import os
        
        # Kontrollera att API-nyckel finns
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            st.error("OPENAI_API_KEY saknas i milj√∂variabler")
            return None
            
        client = OpenAI(api_key=api_key)
        
        with open(audio_file_path, "rb") as audio_file:
            response = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file
            )
        return response.text
    except Exception as e:
        st.error(f"Fel vid transkribering: {e}")
        return None

def split_audio_file(audio_file_path, segment_duration_minutes=15):
    """
    Dela upp en ljudfil i segment f√∂r transkribering.
    Returnerar lista med s√∂kv√§gar till segment-filer.
    """
    try:
        from pydub import AudioSegment
        import math
        
        # Ladda ljudfilen
        audio = AudioSegment.from_file(audio_file_path)
        
        # Ber√§kna segment-l√§ngd i millisekunder
        segment_length_ms = segment_duration_minutes * 60 * 1000
        
        # Ber√§kna antal segment
        total_length_ms = len(audio)
        num_segments = math.ceil(total_length_ms / segment_length_ms)
        
        segment_paths = []
        base_path = audio_file_path.rsplit('.', 1)[0]
        
        for i in range(num_segments):
            start_ms = i * segment_length_ms
            end_ms = min((i + 1) * segment_length_ms, total_length_ms)
            
            # Extrahera segment
            segment = audio[start_ms:end_ms]
            
            # Spara segment
            segment_path = f"{base_path}_segment_{i+1}.wav"
            segment.export(segment_path, format="wav")
            segment_paths.append(segment_path)
        
        return segment_paths
        
    except Exception as e:
        st.error(f"Fel vid segmentering av ljudfil: {e}")
        return []

def transcribe_large_audio_file(audio_file_path):
    """
    Transkribera en stor ljudfil genom att dela upp den i segment.
    Returnerar sammanslagen transkribering.
    """
    try:
        # Dela upp filen i 15-minuters segment
        st.info("üîÑ Delar upp ljudfilen i 15-minuters segment f√∂r optimal transkribering...")
        segment_paths = split_audio_file(audio_file_path, segment_duration_minutes=15)
        
        if not segment_paths:
            st.error("Kunde inte dela upp ljudfilen")
            return None
        
        st.info(f"üìÇ Skapade {len(segment_paths)} segment f√∂r transkribering")
        
        # Transkribera varje segment
        transcriptions = []
        for i, segment_path in enumerate(segment_paths):
            st.info(f"üéØ Transkriberar segment {i+1} av {len(segment_paths)}...")
            
            transcription = transcribe_audio_openai(segment_path)
            if transcription:
                transcriptions.append(f"[Segment {i+1}]\n{transcription}")
            else:
                st.warning(f"‚ö†Ô∏è Segment {i+1} kunde inte transkriberas")
            
            # Rensa segment-fil efter transkribering
            try:
                os.remove(segment_path)
            except:
                pass
        
        if transcriptions:
            # Sl√• ihop alla transkribering
            full_transcription = "\n\n".join(transcriptions)
            st.success(f"‚úÖ Transkribering klar f√∂r alla {len(transcriptions)} segment!")
            return full_transcription
        else:
            st.error("‚ùå Ingen transkribering lyckades")
            return None
            
    except Exception as e:
        st.error(f"Fel vid segmenterad transkribering: {e}")
        return None

def get_audio_duration(audio_file_path):
    """
    H√§mta ljudfilens l√§ngd (sekunder). Kr√§ver pydub.
    """
    try:
        from pydub import AudioSegment
        audio = AudioSegment.from_file(audio_file_path)
        return round(audio.duration_seconds)
    except:
        return None

def format_duration(seconds: int):
    """
    Formatera sekunder till "Xm Ys" eller "Ys".
    """
    minutes = seconds // 60
    seconds = seconds % 60
    if minutes:
        return f"{minutes}m {seconds}s"
    else:
        return f"{seconds}s"

def validate_audio_file(uploaded_file, max_duration_seconds=36):
    """
    Kontrollera att uppladdad fil √§r under maxstorlek (MB).
    """
    max_size_mb = 100  # √ñkat fr√•n 5 MB till 100 MB f√∂r l√§ngre samtal
    if uploaded_file.size > max_size_mb * 1024 * 1024:
        return False, f"Filen √§r f√∂r stor. Max: {max_size_mb} MB."
    return True, "OK"

def display_audio_player(audio_file_path):
    """
    Visa en Streamlit-spelare f√∂r den sparade ljudfilen.
    """
    if audio_file_path and os.path.exists(audio_file_path):
        with open(audio_file_path, 'rb') as f:
            audio_bytes = f.read()
            st.audio(audio_bytes, format='audio/wav')
        dur = get_audio_duration(audio_file_path)
        if dur:
            st.caption(f"L√§ngd: {format_duration(dur)}")

def record_audio_streamlit(session_id, step_number, key_prefix=""):
    """
    Spela in ljud med streamlit-webrtc komponenten.
    Returnerar inspelade ljudet som bytes, annars None.
    """
    st.write("üé§ **Ljudinspelning:**")
    
    try:
        from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
        import av
        import numpy as np
        import io
        import wave
        
        # WebRTC konfiguration
        rtc_configuration = RTCConfiguration({
            "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
        })
        
        component_key = f"{key_prefix}_webrtc_{session_id}_{step_number}"
        
        # Skapa en container f√∂r ljuddata
        if f"audio_frames_{component_key}" not in st.session_state:
            st.session_state[f"audio_frames_{component_key}"] = []
        
        def audio_frame_callback(frame):
            """Callback f√∂r att samla ljudframes"""
            audio_array = frame.to_ndarray()
            st.session_state[f"audio_frames_{component_key}"].append(audio_array)
            return frame
        
        # WebRTC streamer f√∂r ljudinspelning
        webrtc_ctx = webrtc_streamer(
            key=component_key,
            mode=WebRtcMode.SENDONLY,
            audio_frame_callback=audio_frame_callback,
            rtc_configuration=rtc_configuration,
            media_stream_constraints={"video": False, "audio": True},
            async_processing=True,
        )
        
        if webrtc_ctx.state.playing:
            st.info("üî¥ Spelar in... Klicka 'STOP' n√§r du √§r klar")
        elif not webrtc_ctx.state.playing and len(st.session_state[f"audio_frames_{component_key}"]) > 0:
            # Konvertera frames till WAV-bytes
            audio_frames = st.session_state[f"audio_frames_{component_key}"]
            if audio_frames:
                # Kombinera alla frames
                audio_data = np.concatenate(audio_frames, axis=0)
                
                # Konvertera till WAV-format
                sample_rate = 48000  # WebRTC standard
                audio_bytes_io = io.BytesIO()
                
                with wave.open(audio_bytes_io, 'wb') as wav_file:
                    wav_file.setnchannels(1)  # Mono
                    wav_file.setsampwidth(2)  # 16-bit
                    wav_file.setframerate(sample_rate)
                    
                    # Konvertera float till int16
                    audio_int16 = (audio_data * 32767).astype(np.int16)
                    wav_file.writeframes(audio_int16.tobytes())
                
                audio_bytes = audio_bytes_io.getvalue()
                
                st.success("‚úÖ Ljudinspelning klar!")
                st.audio(audio_bytes, format="audio/wav")
                
                # Rensa frames f√∂r n√§sta inspelning
                st.session_state[f"audio_frames_{component_key}"] = []
                
                return audio_bytes
        else:
            st.info("Klicka p√• 'START' f√∂r att b√∂rja spela in ljud")
            
        return None
            
    except ImportError:
        # Fallback: Visa instruktioner f√∂r manuell uppladdning
        st.warning("‚ö†Ô∏è Ljudinspelningskomponenten √§r inte tillg√§nglig.")
        st.info("""
        **Alternativ f√∂r ljudinspelning:**
        1. Anv√§nd din telefon eller dator f√∂r att spela in ljud
        2. Spara filen som .wav eller .mp3
        3. Ladda upp filen med filuppladdaren ovan
        """)
        return None
    except Exception as e:
        st.error(f"Fel vid ljudinspelning: {e}")
        st.info("""
        **Alternativ f√∂r ljudinspelning:**
        1. Anv√§nd din telefon eller dator f√∂r att spela in ljud
        2. Spara filen som .wav eller .mp3
        3. Ladda upp filen med filuppladdaren ovan
        """)
        return None

def record_and_transcribe_audio(session_id, step_number, key_prefix=""):
    """
    Ljudinspelning med Streamlits inbyggda st.audio_input.
    Returnerar tuple: (audio_file_path, transcription_text)
    """
    st.write("üé§ **Ljudinspelning:**")
    
    # Varning f√∂r l√•nga samtal
    st.info("üí° **Tips f√∂r l√•nga samtal (√∂ver 15 min):** Systemet hanterar automatiskt segmentering och transkribering f√∂r optimala resultat.")
    
    # F√∂rs√∂k anv√§nda Streamlits inbyggda audio_input f√∂rst
    try:
        component_key = f"{key_prefix}_audio_input_{session_id}_{step_number}"
        
        # Anv√§nd Streamlits inbyggda ljudinspelning
        audio_bytes = st.audio_input("Spela in ljud", key=component_key)
        
        if audio_bytes is not None:
            st.success("‚úÖ Ljudinspelning mottagen!")
            st.audio(audio_bytes, format="audio/wav")
            
            # Kontrollera filstorlek och l√§ngd
            file_size_mb = len(audio_bytes.getvalue()) / (1024 * 1024)
            st.info(f"üìä Filstorlek: {file_size_mb:.1f} MB")
            
            # Spara ljudfilen automatiskt
            with st.spinner("Sparar ljudfil..."):
                audio_file_path = save_recorded_audio(audio_bytes.getvalue(), session_id, step_number)
            
            if audio_file_path:
                st.success(f"üíæ Ljudfil sparad: {os.path.basename(audio_file_path)}")
                
                # Kontrollera om filen beh√∂ver segmenteras f√∂r transkribering
                if file_size_mb > 20:  # Om filen √§r st√∂rre √§n 20 MB, segmentera den
                    st.info("üîÑ Stor fil uppt√§ckt - anv√§nder segmenterad transkribering f√∂r b√§sta resultat...")
                    transcription = transcribe_large_audio_file(audio_file_path)
                else:
                    # Transkribera normalt f√∂r mindre filer
                    with st.spinner("Transkriberar ljud med OpenAI Whisper..."):
                        transcription = transcribe_audio_openai(audio_file_path)
                
                if transcription:
                    st.success("‚úÖ Transkribering klar!")
                    st.markdown("### üìù Transkribering:")
                    st.write(transcription)
                    
                    return audio_file_path, transcription
                else:
                    st.error("‚ùå Transkribering misslyckades")
                    return audio_file_path, None
            else:
                st.error("‚ùå Kunde inte spara ljudfil")
                return None, None
        else:
            st.info("Klicka p√• mikrofon-ikonen ovan f√∂r att spela in ljud")
            return None, None
            
    except Exception as e:
        # Fallback till WebRTC f√∂r lokal utveckling
        st.warning("‚ö†Ô∏è Inbyggd ljudinspelning inte tillg√§nglig. F√∂rs√∂ker WebRTC...")
        
        try:
            from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
            import av
            import numpy as np
            import io
            import wave
            
            # WebRTC konfiguration
            rtc_configuration = RTCConfiguration({
                "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
            })
            
            component_key = f"{key_prefix}_webrtc_{session_id}_{step_number}"
            
            # Skapa en container f√∂r ljuddata
            if f"audio_frames_{component_key}" not in st.session_state:
                st.session_state[f"audio_frames_{component_key}"] = []
            
            # Skapa state f√∂r att h√•lla koll p√• om vi redan har processat denna inspelning
            processed_key = f"processed_{component_key}"
            if processed_key not in st.session_state:
                st.session_state[processed_key] = False
            
            def audio_frame_callback(frame):
                """Callback f√∂r att samla ljudframes"""
                audio_array = frame.to_ndarray()
                st.session_state[f"audio_frames_{component_key}"].append(audio_array)
                return frame
            
            # WebRTC streamer f√∂r ljudinspelning
            webrtc_ctx = webrtc_streamer(
                key=component_key,
                mode=WebRtcMode.SENDONLY,
                audio_frame_callback=audio_frame_callback,
                rtc_configuration=rtc_configuration,
                media_stream_constraints={"video": False, "audio": True},
                async_processing=True,
            )
            
            if webrtc_ctx.state.playing:
                st.info("üî¥ Spelar in... Klicka 'STOP' n√§r du √§r klar")
                # Reset processed state n√§r vi b√∂rjar en ny inspelning
                st.session_state[processed_key] = False
                
            elif not webrtc_ctx.state.playing and len(st.session_state[f"audio_frames_{component_key}"]) > 0 and not st.session_state[processed_key]:
                # Konvertera frames till WAV-bytes
                audio_frames = st.session_state[f"audio_frames_{component_key}"]
                if audio_frames:
                    with st.spinner("Bearbetar ljudinspelning..."):
                        # Kombinera alla frames
                        audio_data = np.concatenate(audio_frames, axis=0)
                        
                        # Konvertera till WAV-format
                        sample_rate = 48000  # WebRTC standard
                        audio_bytes_io = io.BytesIO()
                        
                        with wave.open(audio_bytes_io, 'wb') as wav_file:
                            wav_file.setnchannels(1)  # Mono
                            wav_file.setsampwidth(2)  # 16-bit
                            wav_file.setframerate(sample_rate)
                            
                            # Konvertera float till int16
                            audio_int16 = (audio_data * 32767).astype(np.int16)
                            wav_file.writeframes(audio_int16.tobytes())
                        
                        audio_bytes = audio_bytes_io.getvalue()
                    
                    st.success("‚úÖ Ljudinspelning klar!")
                    st.audio(audio_bytes, format="audio/wav")
                    
                    # Spara ljudfilen automatiskt
                    with st.spinner("Sparar ljudfil..."):
                        audio_file_path = save_recorded_audio(audio_bytes, session_id, step_number)
                    
                    if audio_file_path:
                        st.success(f"üíæ Ljudfil sparad: {os.path.basename(audio_file_path)}")
                        
                        # Kontrollera filstorlek f√∂r segmentering
                        file_size_mb = len(audio_bytes) / (1024 * 1024)
                        st.info(f"üìä Filstorlek: {file_size_mb:.1f} MB")
                        
                        # Transkribera automatiskt med segmentering f√∂r stora filer
                        if file_size_mb > 20:
                            st.info("üîÑ Stor fil uppt√§ckt - anv√§nder segmenterad transkribering f√∂r b√§sta resultat...")
                            transcription = transcribe_large_audio_file(audio_file_path)
                        else:
                            with st.spinner("Transkriberar ljud med OpenAI Whisper..."):
                                transcription = transcribe_audio_openai(audio_file_path)
                        
                        if transcription:
                            st.success("‚úÖ Transkribering klar!")
                            st.markdown("### üìù Transkribering:")
                            st.write(transcription)
                            
                            # Markera som processat
                            st.session_state[processed_key] = True
                            
                            # Rensa frames f√∂r n√§sta inspelning
                            st.session_state[f"audio_frames_{component_key}"] = []
                            
                            return audio_file_path, transcription
                        else:
                            st.error("‚ùå Transkribering misslyckades")
                            return audio_file_path, None
                    else:
                        st.error("‚ùå Kunde inte spara ljudfil")
                        return None, None
            else:
                st.info("Klicka p√• 'START' f√∂r att b√∂rja spela in ljud")
                
            return None, None
                
        except Exception as e2:
            # Sista fallback
            st.error("‚ùå Ingen ljudinspelningsmetod tillg√§nglig.")
            st.info("""
            **Alternativ f√∂r ljudinspelning:**
            1. Anv√§nd din telefon eller dator f√∂r att spela in ljud
            2. Spara filen som .wav eller .mp3
            3. Ladda upp filen med filuppladdaren ovan
            """)
            return None, None